{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93c84db9-d22a-4648-8c2b-8ab3110c0658",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import timm\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f9398a8-4be5-447c-9eff-cac5838fa98b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/bc3603/my_env/lib/python3.11/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "# configs\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "batch_size = 64\n",
    "num_workers = 4\n",
    "image_size = 224\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    ),\n",
    "])\n",
    "\n",
    "val_dir = '/scratch/bc3603/imagenet1k/val/imagenet-val'\n",
    "\n",
    "val_dataset = datasets.ImageFolder(root=val_dir, transform=transform)\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers\n",
    ")\n",
    "\n",
    "model_names = {\n",
    "    'ConvNeXt-Tiny': 'convnext_tiny',\n",
    "    'ViT-Small': 'vit_small_patch16_224',\n",
    "    'ResNet50': 'resnet50',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0741cc9d-5b68-4766-ac5d-43df005b2317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNeXt-Tiny: 28.59M parameters\n",
      "ViT-Small: 22.05M parameters\n",
      "ResNet50: 25.56M parameters\n"
     ]
    }
   ],
   "source": [
    "for name, timm_name in model_names.items():\n",
    "    model = timm.create_model(timm_name, pretrained=False)\n",
    "    num_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"{name}: {num_params / 1e6:.2f}M parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bef84425-ca62-45a2-8824-d091c9d4e5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(val_loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    return 100 * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7c11304-1f63-46b3-b53b-202bd3830446",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [07:24<00:00,  1.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNeXt-Tiny Top-1 Accuracy: 84.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3da0156f3ac848f1aa94ea1ecd52521d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/88.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [07:20<00:00,  1.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ViT-Small Top-1 Accuracy: 74.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [07:20<00:00,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet50 Top-1 Accuracy: 80.12%\n",
      "\n",
      "--- Final Accuracy ---\n",
      "ConvNeXt-Tiny: 84.00%\n",
      "ViT-Small: 74.64%\n",
      "ResNet50: 80.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "for name, timm_name in model_names.items():\n",
    "    model = timm.create_model(timm_name, pretrained=True)\n",
    "    model.to(device)\n",
    "\n",
    "    acc = evaluate(model)\n",
    "    results[name] = acc\n",
    "    print(f\"{name} Top-1 Accuracy: {acc:.2f}%\")\n",
    "\n",
    "print(\"\\n--- Final Accuracy ---\")\n",
    "for name, acc in results.items():\n",
    "    print(f\"{name}: {acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b39f64e9-00ef-4ad0-b068-f31581309c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TinyViT loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/scratch/bc3603/MLfinal/tiny_vit_repo')\n",
    "\n",
    "from models import tiny_vit  # model file is under tiny_vit_repo/models/tiny_vit.py\n",
    "import torch\n",
    "\n",
    "vit = tiny_vit.tiny_vit_21m_224(pretrained=False)\n",
    "\n",
    "checkpoint = torch.load('/scratch/bc3603/MLfinal/tiny_vit_21m_22kto1k_distill.pth', map_location='cpu')\n",
    "vit.load_state_dict(checkpoint['model'])\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "vit = vit.to(device)\n",
    "vit.eval()\n",
    "\n",
    "print(\"TinyViT loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6b455d57-3cf1-4b6a-a598-64794646649d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [07:28<00:00,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TinyViT-21M Top-1 Accuracy: 84.59%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(val_loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    return 100 * correct / total\n",
    "vit_acc = evaluate(vit)\n",
    "print(f\"TinyViT-21M Top-1 Accuracy: {vit_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b30ebe4c-323b-4ea7-b6cd-071d54c261e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/bc3603/MLfinal/convnext_repo/models/convnext.py:158: UserWarning: Overwriting convnext_tiny in registry with models.convnext.convnext_tiny. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  @register_model\n",
      "/scratch/bc3603/MLfinal/convnext_repo/models/convnext.py:167: UserWarning: Overwriting convnext_small in registry with models.convnext.convnext_small. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  @register_model\n",
      "/scratch/bc3603/MLfinal/convnext_repo/models/convnext.py:176: UserWarning: Overwriting convnext_base in registry with models.convnext.convnext_base. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  @register_model\n",
      "/scratch/bc3603/MLfinal/convnext_repo/models/convnext.py:185: UserWarning: Overwriting convnext_large in registry with models.convnext.convnext_large. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  @register_model\n",
      "/scratch/bc3603/MLfinal/convnext_repo/models/convnext.py:194: UserWarning: Overwriting convnext_xlarge in registry with models.convnext.convnext_xlarge. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  @register_model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNeXt-Tiny loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import importlib\n",
    "\n",
    "if '/scratch/bc3603/MLfinal/tiny_vit_repo' in sys.path:\n",
    "    sys.path.remove('/scratch/bc3603/MLfinal/tiny_vit_repo')\n",
    "sys.path.append('/scratch/bc3603/MLfinal/convnext_repo')\n",
    "if 'models' in sys.modules:\n",
    "    del sys.modules['models']\n",
    "\n",
    "from models import convnext\n",
    "import torch\n",
    "\n",
    "convnext = convnext.convnext_tiny(num_classes=1000)\n",
    "\n",
    "checkpoint = torch.load('/scratch/bc3603/MLfinal/convnext_tiny_22k_1k_224.pth', map_location='cpu')\n",
    "convnext.load_state_dict(checkpoint['model'])\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "convnext = convnext.to(device)\n",
    "convnext.eval()\n",
    "\n",
    "print(\"ConvNeXt-Tiny loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f4d909b5-2ef0-44c8-9418-f93e90e5ea78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [07:30<00:00,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNeXt-Tiny Top-1 Accuracy: 82.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "convnext_acc = evaluate(convnext)\n",
    "print(f\"ConvNeXt-Tiny Top-1 Accuracy: {convnext_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99e22b90-10dc-4a7b-a27d-0a732db2eaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_transform = transforms.Compose([\n",
    "    transforms.Resize(448),\n",
    "    transforms.CenterCrop(448),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.5, 0.5, 0.5],\n",
    "        std=[0.5, 0.5, 0.5]\n",
    "    ),\n",
    "])\n",
    "val_dataset = datasets.ImageFolder(root=val_dir, transform=res_transform)\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45ba82d0-5e13-412b-9225-35d42bb8c547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNetV2-50x1 loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "resnet = timm.create_model(\n",
    "    'hf-hub:timm/resnetv2_50x1_bit.goog_in21k_ft_in1k',\n",
    "    pretrained=True\n",
    ")\n",
    "\n",
    "resnet = resnet.to(device)\n",
    "resnet.eval()\n",
    "\n",
    "print(\"ResNetV2-50x1 loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f756ffd-0352-4178-91b1-ff83d36e7682",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [12:04<00:00,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNetV2-50x1 Top-1 Accuracy: 80.34%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "resnet_acc = evaluate(resnet)\n",
    "print(f\"ResNetV2-50x1 Top-1 Accuracy: {resnet_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9388a2c5-3b5e-40bc-bfaf-3202af34cce6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
